{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3885c8b7-7ee0-469e-9e69-08dea65e5892",
   "metadata": {},
   "source": [
    "# Create API scraper  - For reddit\n",
    "This script scrapes defined subreddits of your choice from reddit. It only scrapes the title and body of posts. \n",
    "It doesn't scrape any usernames, nor any comments. You can change what type of posts you want to use, like hot, new, top.\n",
    "I also made it skip the first three top posts, since they are often moderator stickied posts. I don't know how to ignore those, so skipping them was easier. It means some of these might be scraped if there's more than three. You can set the number of posts, and change where to save the file and format. This saves it as a csv file in my directory. \n",
    "\n",
    "### Step 1. Find reddit's API tool\n",
    "Define your Reddit API credentials - You create an \"app\" from this developer link https://old.reddit.com/prefs/apps\n",
    "### Step 1: Name your app \n",
    "Under Redirect URI, put in: http://localhost (required, even if not used in this script)\n",
    "\n",
    "optionals: add description\n",
    "### Step 2: Retrieve Credentials\n",
    "After creating the app, youâ€™ll see your new app listed. Take note of the following:\n",
    "\n",
    "   * Client ID: Located just below your app name (a string of characters).\n",
    "   * Client Secret: Found next to the \"secret\" label.\n",
    "   * User Agent: A string describing your application. Use something like \"MyRedditScraper/1.0 by [your_reddit_username]\".\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ba3ca-e533-4036-b647-a61bf8f0512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d66cef64-b2c8-4913-8f11-afabc78c427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Mental_data/schizophrenia_posts.csv\n"
     ]
    }
   ],
   "source": [
    "# Put in creditionals from the app you created through reddit API\n",
    "CLIENT_ID = 'your client id here'\n",
    "CLIENT_SECRET = 'your client secret here'\n",
    "USER_AGENT = '\"MyRedditScraper\"'\n",
    "\n",
    "# Initialize the Reddit API client\n",
    "reddit = praw.Reddit(\n",
    "    client_id=CLIENT_ID,\n",
    "    client_secret=CLIENT_SECRET,\n",
    "    user_agent=USER_AGENT\n",
    ")\n",
    "\n",
    "def scrape_subreddit(subreddit_name, limit=100):\n",
    "    \"\"\"\n",
    "    Scrapes text bodies of posts from a subreddit.\n",
    "\n",
    "    Args:\n",
    "        subreddit_name (str): Name of the subreddit to scrape.\n",
    "        limit (int): Maximum number of posts to scrape.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing indexed posts with text bodies.\n",
    "    \"\"\"\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "\n",
    "    for idx, submission in enumerate(subreddit.hot(limit=limit)):\n",
    "        if idx < 3:  # Skip the first 3 posts\n",
    "            continue\n",
    "        post_data = {\n",
    "            'Index': idx + 1,\n",
    "            'Title': submission.title,\n",
    "            'Body': submission.selftext\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(posts)\n",
    "\n",
    "# Define Subreddit to scrape from\n",
    "if __name__ == \"__main__\":\n",
    "    subreddit_name = \"schizophrenia\"  # Replace with your desired subreddit\n",
    "    post_limit = 50  # Number of posts to scrape\n",
    "\n",
    "    data = scrape_subreddit(subreddit_name, limit=post_limit)\n",
    "\n",
    "    # Specify the folder to save the file\n",
    "    output_folder = \"Mental_data\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "   \n",
    "    # Save the data to a CSV file\n",
    "    output_file = os.path.join(output_folder, f\"{subreddit_name}_posts.csv\")\n",
    "    data.to_csv(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
